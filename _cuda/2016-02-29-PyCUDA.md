---
layout: post
title:  "PyCUDA"
date:   2016-02-29 0:10:00
categories: CUDA Programming
description: Python 개발환경에서 CUDA 프로그래밍을 위한 라이브러리
tags:
 - CUDA
 - Python
---

[PyCUDA](https://pypi.python.org/pypi/pycuda)는 CUDA 가속을 Python 프로그램에서도 활용할 수 있도록 하기 위해서 만들어진 Python library이다. PyCUDA는 Python을 위한 CUDA Wrapper와 같은 것으로, Python으로 변형된 CUDA 프로그래밍 언어가 아니다. Python에서 CUDA를 이용하려면, 일반 C 모듈을 로딩하는 것과 같이 모듈화 부터 시작해주어야 하지만, PyCUDA를 이용한다면 그런 복잡한 절차 없이 곧바로 CUDA 프로그래밍을 할 수게 된다. 다만 CUDA C는 공부해야만 한다.
[[Document](https://documen.tician.de/pycuda/)]

### 설치

#### PyCUDA 다운로드
```
git clone --recursive http://git.tiker.net/trees/pycuda.git
cd pycuda
```
또는

```
https://pypi.python.org/packages/source/p/pycuda/pycuda-2015.1.3.tar.gz
tar -xzvf pycuda-2015.1.3.tar.gz
cd pycuda
```

**Prerequisites**

* [Boost](http://www.boost.org/) - ``` sudo apt-get install libboost-all-dev```
* CUDA
* [Numpy](http://numpy.org/) - ``` sudo pip install numpy ```

### Build 및 설치
```
cd pycuda-VERSION
./configure.py --cuda-root=/usr/local/cuda --cudadrv-lib-dir=/usr/lib --boost-inc-dir=/usr/include --boost-lib-dir=/usr/lib --boost-python-libname=boost_python-py27 --boost-thread-libname=boost_thread
make -j 4
sudo python setup.py install
sudo pip install .
```

> 이때 환경변수 설정 등으로 컴파일이나 설치가 정상적으로 되지 않는 경우가 있는데,
root의 path를 수정해주어야 한다. 이전까지 ubuntu에 설정한 환경변수가 user level이었던 것도 있고, 모든 경로가 설정되지 않은 탓도 있다.

>{% highlight bash %}
#.bashrc 마지막 부분에 추가
export PATH="/usr/local/cuda/bin":$PATH
export CUDA_ROOT="/usr/local/cuda/bin"
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:"/usr/local/cuda/lib64"
export CUDA_INC_DIR="/usr/local/cuda/include"
{% endhighlight %}

### [Tutorial](https://documen.tician.de/pycuda/tutorial.html)

#### 불러오기

{% highlight python linenos %}
import pycuda.driver as cuda
import pycuda.autoinit
from pycuda.compiler import SourceModule
{% endhighlight %}

#### Transfering Data
CUDA는 GPU와 CPU간에 데이터를 복사하는 명령이 존재한다. 처리하는 코어가 다르고, 저장되는 위치가 다르므로 CUDA를 실행하기 전에 반드시 Data를 복사하고 처리후에 가져오는 작업을 해야만 한다.

PyCUDA에서는 호스트 메모리 상에 있는 `numpy`의 **array**를 복사해서 사용한다.

{% highlight python linenos %}
import numpy
a_in = numpy.random.randn(4,4)
{% endhighlight %}

여기서 주의할 사항은 nVidia CUDA Core들은 주로 Single Precision을 지원하도록 되어 있기에, **a_in**의 데이터 타입을 single precision으로 해주는 것이 성능향상에 도움이 된다.

{% highlight python linenos %}
a_in = a_in.astype(numpy.float32)
{% endhighlight %}

이제 Host(CPU)에서 데이터가 준비되었으니 Device(GPU)에 메모리를 할당하고 데이터를 전송해보자.

{% highlight python linenos %}
a_d = cuda.mem_alloc(a_in.nbytes)
cuda.memcpy_htod(a_d, a_in)
{% endhighlight %}

반대로 Device에서 Host로 데이터를 가져오는 명령어는 다음과 같다.
numpy에서 버퍼를 만들고 그대로 가져오면 된다.

{% highlight python linenos %}
a_out = numpy.empty_like(a_in)
cuda.memcpy_dtoh(a_out, a_d)
{% endhighlight %}

#### Kernel 실행하기
CUDA를 동작시키는 함수를 Kernel이라고 부른다. 보통 CUDA C에서는 `cu`파일에 kernel 코드를 작성하는데, PyCUDA에서는 그렇게 할 필요없이 Python 파일에 코드를 추가할 수 있다. 다만 Python 파일에 있다고, Kernel 함수의 언어도 Python이 되는 것은 아니고, 이 부분에 대해서는 CUDA C 코드를 작성해야 한다.

{% highlight python linenos %}
mod = SourceModule("""
  __global__ void doublify(float *a)
  {
    int idx = threadIdx.x + threadIdx.y*4;
    a[idx] *= 2;
  }
  """)
{% endhighlight %}

여기서 **SourceModule**은 앞에 초기화할때 불러들인 CUDA Compiler Class로, 초기화하는 절차를 통해 String 형태로 작성된 CUDA 코드를 런타임에 컴파일한다. **mod**에는 컴파일된 CUDA 함수의 인스턴스가 있으며 다음 코드를 통해, CUDA 함수의 인스턴스를 얻고 커널을 실행시킬 수 있다.

여기서 CUDA block의 크기는 예제에서 사용할 데이터의 크기인 *4x4*로 한다.

{% highlight python linenos %}
func = mod.get_function("doublify")
func(a_d, block=(4,4,1))
{% endhighlight %}

#### 단순한 버전
PyCUDA는 데이터 복사하는 부분에 대하여 보다 단순한 방법을 제공하는데, 지금까지 Tutorial에서 설명한 내용을 다음과 같이 요약할 수 있다.

이렇게 메모리를 할당하고 복사하고 했던 과정을,
{% highlight python linenos %}
a_d = cuda.mem_alloc(a.nbytes)
cuda.memcpy_htod(a_d, a_in)

func = mod.get_function("doublify")
func(a_d, block=(4,4,1))

a_out = numpy.empty_like(a_in)
cuda.memcpy_dtoh(a_out, a_d)
{% endhighlight %}

아래와 같이 바꿀 수 있다.
{% highlight python linenos %}
func = mod.get_function("doublify")
func(cuda.InOut(a, block=(4,4,1))
{% endhighlight %}

### PyCUDA Sample
PyCUDA의 문서로 Python에서는 CUDA Programming을 어떻게 할 수 있는지 살펴보자.

{% highlight python linenos %}
# (from PyCUDA's documentation)

# Import PyCuda and Initialize
import pycuda.autoinit
import pycuda.driver as drv
import numpy

from pycuda.compiler import SourceModule
mod = SourceModule("""
__global__ void multiply_them(float *dest, float *a, float *b)
{
  const int i = threadIdx.x;
  dest[i] = a[i] * b[i];
}
""")

multiply_them = mod.get_function("multiply_them")

a = numpy.random.randn(400).astype(numpy.float32)
b = numpy.random.randn(400).astype(numpy.float32)

dest = numpy.zeros_like(a)
multiply_them(
        drv.Out(dest), drv.In(a), drv.In(b),
        block=(400,1,1), grid=(1,1))

assert numpy.allclose(dest, a*b)
print(dest)
{% endhighlight %}



살펴보면 C/C++ 예제에서는 Device Memory로 copy했던 것을 위 code block에서 21번째 줄에서 보는 것과 같이 ```drv.Out```과 ```drv.In```으로 구동하는 것을 볼 수 있다. 또한 CUDA 동작을 지정했던 명령어 라인도 Parameter로 입력한다.

따라서 PyCUDA에서는 C/C++ CUDA에서 했던 것보다 많은 부분에서 성가신 부분에 대해 보다 간략한 코딩을 할 수 있게 됨을 알 수 있다.

주목할 점은 import하는 과정에서 PyCUDA라이브러리에서 CUDA를 초기화하는 과정을 처리해 주며, CUDA Kernel을 하나의 모듈로서 취급을 한다는 것이다. 그 외에는 CUDA 언어는 동일하다는 것을 알 수 있다.



### PyCUDA + Theano
맛보기로 PyCUDA와 Theano를 함께 연동해보자.

{% highlight python %}
import numpy, theano
import theano.misc.pycuda_init
from pycuda.compiler import SourceModule
import theano.sandbox.cuda as cuda

class PyCUDADoubleOp(theano.Op):

    __props__ = ()

    def make_node(self, inp):
        inp = cuda.basic_ops.gpu_contiguous(
           cuda.basic_ops.as_cuda_ndarray_variable(inp))
        assert inp.dtype == "float32"
        return theano.Apply(self, [inp], [inp.type()])

    def make_thunk(self, node, storage_map, _, _2):
        mod = SourceModule("""
    __global__ void my_fct(float * i0, float * o0, int size) {
    int i = blockIdx.x*blockDim.x + threadIdx.x;
    if(i<size){
        o0[i] = i0[i]*2;
    }
  }""")
        pycuda_fct = mod.get_function("my_fct")
        inputs = [storage_map[v] for v in node.inputs]
        outputs = [storage_map[v] for v in node.outputs]

        def thunk():
            z = outputs[0]
            if z[0] is None or z[0].shape != inputs[0][0].shape:
                z[0] = cuda.CudaNdarray.zeros(inputs[0][0].shape)
            grid = (int(numpy.ceil(inputs[0][0].size / 512.)), 1)
            pycuda_fct(inputs[0][0], z[0], numpy.intc(inputs[0][0].size),
                       block=(512, 1, 1), grid=grid)
        return thunk

def main():
  x = theano.tensor.fmatrix()
  f = theano.function([x], PyCUDADoubleOp()(x))  
  xv = numpy.ones((4, 5), dtype="float32")
  print(xv)
  assert numpy.allclose(f(xv), xv*2)  
  print(numpy.asarray(f(xv)))

if __name__ == "__main__":
  main()
{% endhighlight%}

실행결과는 다음과 같다.
![]({{site.info.baseurl}}/images//test_theano_pycuda.png)

[Theano Tutorial for GPU](https://documen.tician.de/pycuda/tutorial.html#transferring-data)
