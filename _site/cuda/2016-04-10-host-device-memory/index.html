<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>CUDA GPU 메모리</title>
    <meta name="description" content="A simple, whitespace, helvetica based portfolio theme.
">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="http://localhost:4000/cuda/2016-04-10-host-device-memory/">

    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
    <line rel="stylesheet" href="/css/solarized_light.css"
    
    <!-- mathjax config similar to math.stackexchange -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$']],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      messageStyle: "none",
      "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
    });
    </script>
    <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
</head>


  <body>
    <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-email" viewBox="0 0 1024 1024"><path class="path1" d="M950.857 859.429v-438.857q-18.286 20.571-39.429 37.714-153.143 117.714-243.429 193.143-29.143 24.571-47.429 38.286t-49.429 27.714-58.571 14h-1.143q-27.429 0-58.571-14t-49.429-27.714-47.429-38.286q-90.286-75.429-243.429-193.143-21.143-17.143-39.429-37.714v438.857q0 7.429 5.429 12.857t12.857 5.429h841.143q7.429 0 12.857-5.429t5.429-12.857zM950.857 258.857v-14t-0.286-7.429-1.714-7.143-3.143-5.143-5.143-4.286-8-1.429h-841.143q-7.429 0-12.857 5.429t-5.429 12.857q0 96 84 162.286 110.286 86.857 229.143 181.143 3.429 2.857 20 16.857t26.286 21.429 25.429 18 28.857 15.714 24.571 5.143h1.143q11.429 0 24.571-5.143t28.857-15.714 25.429-18 26.286-21.429 20-16.857q118.857-94.286 229.143-181.143 30.857-24.571 57.429-66t26.571-75.143zM1024 237.714v621.714q0 37.714-26.857 64.571t-64.571 26.857h-841.143q-37.714 0-64.571-26.857t-26.857-64.571v-621.714q0-37.714 26.857-64.571t64.571-26.857h841.143q37.714 0 64.571 26.857t26.857 64.571z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-rss" viewBox="0 0 805 1024"><path class="path1" d="M219.429 768q0 45.714-32 77.714t-77.714 32-77.714-32-32-77.714 32-77.714 77.714-32 77.714 32 32 77.714zM512 838.286q1.143 16-9.714 27.429-10.286 12-26.857 12h-77.143q-14.286 0-24.571-9.429t-11.429-23.714q-12.571-130.857-105.429-223.714t-223.714-105.429q-14.286-1.143-23.714-11.429t-9.429-24.571v-77.143q0-16.571 12-26.857 9.714-9.714 24.571-9.714h2.857q91.429 7.429 174.857 46t148 103.714q65.143 64.571 103.714 148t46 174.857zM804.571 839.429q1.143 15.429-10.286 26.857-10.286 11.429-26.286 11.429h-81.714q-14.857 0-25.429-10t-11.143-24.286q-6.857-122.857-57.714-233.429t-132.286-192-192-132.286-233.429-58.286q-14.286-0.571-24.286-11.143t-10-24.857v-81.714q0-16 11.429-26.286 10.286-10.286 25.143-10.286h1.714q149.714 7.429 286.571 68.571t243.143 168q106.857 106.286 168 243.143t68.571 286.571z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol><symbol id="icon-angle-down" viewBox="0 0 658 1024"><path class="path1" d="M614.286 420.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l224.571 224.571 224.571-224.571q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"/></symbol><symbol id="icon-github-alt" viewBox="0 0 951 1024"><path class="path1" d="M365.714 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM731.429 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM822.857 694.857q0-68.571-39.429-116.571t-106.857-48q-23.429 0-111.429 12-40.571 6.286-89.714 6.286t-89.714-6.286q-86.857-12-111.429-12-67.429 0-106.857 48t-39.429 116.571q0 50.286 18.286 87.714t46.286 58.857 69.714 34.286 80 16.857 85.143 4h96q46.857 0 85.143-4t80-16.857 69.714-34.286 46.286-58.857 18.286-87.714zM950.857 594.286q0 118.286-34.857 189.143-21.714 44-60.286 76t-80.571 49.143-97.143 27.143-98 12.571-95.429 2.571q-44.571 0-81.143-1.714t-84.286-7.143-87.143-17.143-78.286-29.429-69.143-46.286-49.143-65.714q-35.429-70.286-35.429-189.143 0-135.429 77.714-226.286-15.429-46.857-15.429-97.143 0-66.286 29.143-124.571 61.714 0 108.571 22.571t108 70.571q84-20 176.571-20 84.571 0 160 18.286 60-46.857 106.857-69.143t108-22.286q29.143 58.286 29.143 124.571 0 49.714-15.429 96 77.714 91.429 77.714 227.429z"/></symbol><symbol id="icon-linkedin" viewBox="0 0 1792 1792"><path class="path1" d="M477 625v991h-330v-991h330zm21-306q1 73-50.5 122t-135.5 49h-2q-82 0-132-49t-50-122q0-74 51.5-122.5t134.5-48.5 133 48.5 51 122.5zm1166 729v568h-329v-530q0-105-40.5-164.5t-126.5-59.5q-63 0-105.5 34.5t-63.5 85.5q-11 30-11 81v553h-329q2-399 2-647t-1-296l-1-48h329v144h-2q20-32 41-56t56.5-52 87-43.5 114.5-15.5q171 0 275 113.5t104 332.5z"/></symbol></defs></svg>
    <header class="site-header">

  <div class="wrapper">
    <div class="site-title" >*kimtaesu</div>
      
    <nav class="site-nav">
        
      <div class="trigger">
        <!-- kimtaesu instead of blog -->
        <a class="page-link" href="/">blog</a>

        
          
          <a class="page-link" href="/about/">about</a>
          
        
          
          <a class="page-link" href="/android">Android</a>
          
        
          
        
          
        
          
          <a class="page-link" href="/kotlin">Kotlin</a>
          
        
          
        
          
          <a class="page-link" href="/python">Python</a>
          
        
          
          <a class="page-link" href="/self-improvement/">Self-Improve</a>
          
        

      </div>
    </nav>
  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">CUDA GPU 메모리</h1>
    <p class="post-meta">April 10, 2016</p>
  </header>

  <article class="post-content">
    <p>GPU에서 동작하는 메모리의 종류 및 활용 방법에 대해서 알아보도록 하겠습니다. 이 포스트는 다음과 같은 것들을 다룰 예정입니다.</p>

<ul>
  <li><a href="#device memory">Device 메모리</a></li>
  <li><a href="#shared memory">Shared 메모리</a></li>
  <li><a href="#constant memory">Constant 메모리</a></li>
  <li><a href="#texture memory">Texture &amp; Surface 메모리</a></li>
</ul>

<p><a id="device memory" class="anckor"></a></p>

<h1 id="device-메모리">Device 메모리</h1>

<p>CUDA의 메모리에 대해서 알아보기 전, 먼저 CUDA가 동작하는 환경에 대해서 간략히 짚어보도록 하겠습니다.
앞으로 개발할 환경은 HC(Heterogeneous Computing)또는 HPC(Heterogeneous Processor Computing)라고 불리는, 한가지 이상의 프로세서를 이용하여 컴퓨팅을 이용한 환경입니다. 이는 보통의 프로그램을 개발하는 것과 독립된 동작 환경을 갖고 있는 임베디드 프로그래밍하고는 또 다른 형태의 프로그래밍 개념인데, 보조 연산 프로세서가 있다고 생각하시면 됩니다. 아래 그림을 보고 설명 드리겠습니다.</p>

<p><img class="col two center" src="/images/201604/CUDA_processing_flow_(En).png" /></p>
<div class="col three caption">
CPU와 GPU 동작 순서. (Source: Wikipedia)
</div>

<p>위 그림은 CUDA 코어의 동작 순서를 설명하고 있습니다. 먼저 이 그림의 구성요소를 살펴보면, 두 개의 processing unit이 있고, 두 종류의 Memory가 있습니다. 여기서 각각의 Processing Unit은 자신이 제어할 수 있는 메모리를 독립적으로 갖고 있으며, 서로 제어할 수는 없습니다. 따라서 CUDA에서 구현된 GPU 코드는 GPU 메모리만을 읽고 쓸 수가 있으므로, GPU 코드를 동작하기 전과 후에 GPU 메모리로 데이터를 전송하고 결과를 가져오는 절차가 있어야 합니다. 다음 절에서 이 부분에 대해서 CUDA가 어떤 방법들을 제공하고 있는지 살펴보도록 하겠습니다.</p>

<div class="img_row center">
<img class="col one" src="/images/201604/cpu.jpeg" />
<img class="col one" src="/images/201604/card-front.jpg" />
</div>
<div class="col two caption center">CUDA는 Host(CPU)와 Device(GPU)를 구분하여 개발합니다.</div>

<p>따라서 CUDA에서는 CPU와 GPU를 분리해서 생각하며, CPU를 Host, GPU를 Device라고 부릅니다. 이는 CPU 입장에서 GPU 역시 보조 프로세서이고, 데이터는 기본적으로 CPU 쪽 메모리에 있기 때문에 주인(Host)입장이기 때문입니다. 이와 비슷하게 CPU를 위한 메모리는 Host 메모리, GPU 메모리는 Device 메모리라고 합니다.</p>

<h2 id="할당-및-초기화">할당 및 초기화</h2>

<p>CUDA Host 메모리 할당은 기존의 메모리 할당과 크게 차이가 없습니다.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">float</span><span class="o">*</span> <span class="n">h_A</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span></code></pre></figure>

<p>Device 메모리의 할당은 <code class="highlighter-rouge">cudaMalloc</code>을 사용하여 할당을 합니다.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">float</span> <span class="o">*</span><span class="n">d_A</span><span class="p">;</span>
<span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span></code></pre></figure>

<p>그러면 <strong>h_A</strong>와 <strong>d_A</strong>는 같은 사이즈이지만 각기 <strong>Host</strong>와 <strong>Device</strong>에 메모리를 할당하게 됩니다. 그럼 이를 바탕으로 예제를 살펴보도록 하겠습니다.</p>

<h2 id="cuda-메모리-해제">CUDA 메모리 해제</h2>

<p>그러하면 GPU 메모리에 할당한 Device 메모리는 어떻게 해제할까요. 이를 위해서 CUDA에서는 <strong>cudaFree</strong>라는 함수를 제공하고 있습니다.</p>

<p><code class="highlighter-rouge">cudaFree(void* p_mempry);</code></p>

<h2 id="데이터-복사">데이터 복사</h2>

<p>CUDA 함수를 실행하기 이전에 또는 CUDA 동작의 결과물을 가져오기 위해서 CUDA 메모리를 복사하는 과정이 반드시 필요하다고 앞에서 말씀드렸었습니다. 이를 위해서 CUDA 에서는 다음과 같은 함수를 제공하고 있습니다.</p>

<p><code class="highlighter-rouge">cudaMemcpy(void* p_dst, void* p_src, int size, int direct)</code></p>

<table>
  <tbody>
    <tr>
      <td>Direct</td>
      <td>내용</td>
    </tr>
    <tr>
      <td>memcpyHostToDevice</td>
      <td>memcpy Host -&gt; Device</td>
    </tr>
    <tr>
      <td>memcpyDeviceToHost</td>
      <td>memcpy Device -&gt; Host</td>
    </tr>
    <tr>
      <td>memcpyDeviceToDevice</td>
      <td>memcpy Device -&gt; Device</td>
    </tr>
    <tr>
      <td>memcpyHostToHost</td>
      <td>memcpy Host -&gt; Host</td>
    </tr>
  </tbody>
</table>

<p>cudaMemcpy함수는 CUDA에서 제공하는 대표적인 메모리 복사 함수입니다. 복사하는 방향을 지정해주는 미리정의된 파라미터가 있다는 것이 특징입니다. 이에 따라서 메모리 주소를 함수에 전달해줄때 어떻게 써야하는지도 신경써야 합니다. 아래 코드를 보시면 이해하실 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span> <span class="n">h_A</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
<span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_A</span><span class="p">,</span> <span class="n">d_A</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<p>Host 메모리에 있는 데이터를 Device 메모리로 복사하게 되는 경우, cudaMalloc으로 할당한 메모리를 dst로, Host 메모리를 src로 전달합니다. 역으로 Device 메모리의 데이터를 Host 메모리로 가져오는 경우에는, 그 반대로 해주어야겠죠. 헷갈리는 것 같으면서도 간단한것 같습니다. 그럼 간단한 예제로 확인해보겠습니다.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42</pre></td><td class="code"><pre><span class="c1">// Device code
</span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">VecAdd</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span> <span class="n">A</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">B</span><span class="p">,</span> <span class="kt">float</span><span class="o">*</span> <span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">)</span>
<span class="p">{</span>
  <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
<span class="p">}</span>

<span class="c1">// Host code
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
<span class="kt">int</span> <span class="n">N</span> <span class="o">=</span> <span class="p">...;</span>
  <span class="kt">size_t</span> <span class="n">size</span> <span class="o">=</span> <span class="n">N</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
  <span class="c1">// Allocate input vectors h_A and h_B in host memory
</span>  <span class="kt">float</span><span class="o">*</span> <span class="n">h_A</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
  <span class="kt">float</span><span class="o">*</span> <span class="n">h_B</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="p">)</span><span class="n">malloc</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
  <span class="c1">// Initialize input vectors
</span><span class="p">...</span>
  <span class="c1">// Allocate vectors in device memory
</span>  <span class="kt">float</span><span class="o">*</span> <span class="n">d_A</span><span class="p">;</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_A</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
  <span class="kt">float</span><span class="o">*</span> <span class="n">d_B</span><span class="p">;</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_B</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
  <span class="kt">float</span><span class="o">*</span> <span class="n">d_C</span><span class="p">;</span>
  <span class="n">cudaMalloc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">d_C</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
  <span class="c1">// Copy vectors from host memory to device memory
</span>  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span> <span class="n">h_A</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_B</span><span class="p">,</span> <span class="n">h_B</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
  <span class="c1">// Invoke kernel
</span>  <span class="kt">int</span> <span class="n">threadsPerBlock</span> <span class="o">=</span> <span class="mi">256</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">blocksPerGrid</span> <span class="o">=</span>
          <span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="n">threadsPerBlock</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">threadsPerBlock</span><span class="p">;</span>
  <span class="n">VecAdd</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocksPerGrid</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_A</span><span class="p">,</span> <span class="n">d_B</span><span class="p">,</span> <span class="n">d_C</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
  <span class="c1">// Copy result from device memory to host memory
</span>  <span class="c1">// h_C contains the result in host memory
</span>  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_C</span><span class="p">,</span> <span class="n">d_C</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
  <span class="c1">// Free device memory
</span>  <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_A</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_B</span><span class="p">);</span>
  <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_C</span><span class="p">);</span>
  <span class="c1">// Free host memory
</span><span class="p">...</span> <span class="p">}</span><span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<div class="col three caption">
CUDA Programming Guide p.22 3.2.2 Device Memory 예제 코드
</div>

<p>line 2-7은 아시다시피 CUDA Kernel 함수입니다. line 15-16에서 host 메모리를, line 20-25에서는 device 메모리를 할당하고 있습니다. 
line 27-28은 CUDA Device Memory로 데이터를 복사하고, line 36에서는 CUDA Kernel의 수행 결과를 다시 Host 메모리로 복사하고 있습니다.
끝으로 line 38 이후는 Device 메모리와 Host 메모리를 해제하고 있습니다. 뭔가 복잡해보이지만 사실 간단하죠?</p>

<p>여기서 Device 메모리는 global 메모리라고도 불립니다. 이렇게 중복적인 용어가 등장하는 이유는 CUDA 문서에서 중복해서 사용하기 때문인데, 이제는 On-chip 메모리를 다루는 상황에서 GPU 코어 입장에서는 global하다고 명명하는 것이 한편으론 타당해 보입니다.</p>

<p>또한 앞으로 CUDA 코딩을 하게 되실 분들에게 강력히 권하는 naming이 있습니다. host 메모리는 <code class="highlighter-rouge">h_</code>로, device 메모리는 <code class="highlighter-rouge">d_</code>로 시작합니다. 짐작하시겠지만, <code class="highlighter-rouge">h_</code>는 host 메모리, <code class="highlighter-rouge">d_</code>는 device 메모리입니다. 이는 포인터 주소같은 것으로는 어디에 할당된 것인지 알 수 없기 때문에, 변수 명으로 구분할 수 밖에 없습니다. 다른 각자의 방법을 고안해서 사용하시거나 회사에서 이미 정해놓은 방법이 있다면 그것을 따르셔도 됩니다만, 기본적으로는 이런식으로 변수명으로 관리를 하시는 것을 권합니다. 또한 CUDA 프로그래밍에서는 다양한 종류의 메모리를 적재적소에 사용하는 것이 중요하므로 다양한 종류의 메모리들이 어떤 메모리에 저장되어 있는지 구별하기 위해서도 이런식의 명명을 따르는 것이 여러모로 유용합니다.</p>

<p><a id="shared memory" class="anckor"></a></p>

<h1 id="shared-메모리">Shared 메모리</h1>

<p>Shared 메모리는 CUDA On-chip 메모리 중에서 L1캐시와 같은 역할을 합니다. CPU와 가장 큰 차이는, CPU에서는 캐시의 데이터를 스스로 관리를 하지만, CUDA의 L1 캐시라고 불리는 Shared 메모리는 CUDA 코드로 직접 어떤 데이터를 넣을 것인지 명시를 해야만 합니다. 이런 구성이 갖는 장점은 다음과 같습니다.</p>

<ol>
  <li>필요한 만큼의 데이터만을 읽어오게 할 수 있다.</li>
  <li>global 메모리 접근에 의한 지연시간 감소</li>
  <li>global 메모리의 대역폭 소모 최적화</li>
</ol>

<p>또한 shared 메모리는 다음과 같은 특징이 있습니다.</p>

<ol>
  <li>CUDA Thread Block 간에서만 데이터 공유가 가능</li>
  <li>CUDA Computability에 따라 캐시의 크기가 다름</li>
  <li></li>
</ol>

<p><a id="constant memory" class="anckor"></a></p>

<h1 id="constant-메모리">Constant 메모리</h1>

<p><a id="texture memory" class="anckor"></a></p>

<h1 id="texture--surface-메모리">Texture &amp; Surface 메모리</h1>


  </article>

  <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20http://localhost:4000/cuda/2016-04-10-host-device-memory/%20via%20&#64;&hashtags=CUDA Memory,CUDA,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook"href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/cuda/2016-04-10-host-device-memory/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=http://localhost:4000/cuda/2016-04-10-host-device-memory/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>
  <section class="comments">
    <h3>Comments</h3>
    <div id="disqus_thread"></div>
</section>
<script type="text/javascript">
    var disqus_loaded = false;

    function load_disqus()
    {
        disqus_loaded = true;
        var disqus_shortname = '';
        var disqus_title = '';
        var disqus_url = '/cuda/2016-04-10-host-device-memory/';
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        var ldr = document.getElementById('disqus_loader');
    };
    window.onscroll = function(e) {
        if ((window.innerHeight + window.scrollY) >= (document.body.offsetHeight - 800)) {
            //hit bottom of page
            if (disqus_loaded==false)
                load_disqus()
        }
    };
</script>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">
  	<p>Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a> and is hosted on <a href="https://github.com" target="_blank">Github</a>.  Theme from <a href="https://github.com/bogoli/-folio" target="_blank">folio</a> by Lia Bogoev, MIT Licence. &#169; 2016.</p>
  </div>

</footer>


  </body>

</html>
